{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984b59e-10af-4a5b-a86f-a4efea5e8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import pickle\n",
    "def sample_frames(video_path, num_frames=10):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_idxs = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    frames = []\n",
    "    for idx in frame_idxs:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        _, frame = video.read()\n",
    "        frames.append(frame)\n",
    "    video.release()\n",
    "    return np.stack(frames)\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def process_folder_sorted(folder_path, pre_slen=10, aft_slen=10, suffix='.gif'):\n",
    "    contents = os.listdir(folder_path)\n",
    "    contents.sort(key=natural_sort_key)\n",
    "\n",
    "    for item in contents:\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"进入子文件夹: {item_path}\")\n",
    "            yield from process_folder_sorted(item_path, pre_slen, aft_slen, suffix)\n",
    "        elif os.path.isfile(item_path) and item.endswith(suffix):\n",
    "            video = sample_frames(item_path, pre_slen + aft_slen)\n",
    "            data_x = video[:pre_slen]\n",
    "            data_y = video[pre_slen:]\n",
    "            data_x = data_x.astype(np.float32) / 255.0 if data_x.max() > 1.0 else data_x\n",
    "            data_y = data_y.astype(np.float32) / 255.0 if data_y.max() > 1.0 else data_y\n",
    "            yield data_x, data_y\n",
    "\n",
    "def save_to_h5(filename, dataset_name, data):\n",
    "    with h5py.File(filename, 'a') as h5f:\n",
    "        if dataset_name in h5f:\n",
    "            dset = h5f[dataset_name]\n",
    "            dset.resize(dset.shape[0] + data.shape[0], axis=0)\n",
    "            dset[-data.shape[0]:] = data\n",
    "        else:\n",
    "            maxshape = (None,) + data.shape[1:]  # Allow unlimited rows\n",
    "            h5f.create_dataset(dataset_name, data=data, maxshape=maxshape, chunks=True)\n",
    "\n",
    "\n",
    "folders = ['train', 'val', 'test']\n",
    "pre_seq_length = 10\n",
    "aft_seq_length = 10\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(os.getcwd(), folder)\n",
    "    batch_size = 10  \n",
    "    data_x_list = []\n",
    "    data_y_list = []\n",
    "    batch_count = 0\n",
    "    for data_x, data_y in process_folder_sorted(folder_path, pre_slen=pre_seq_length, aft_slen=aft_seq_length, suffix='.gif'):\n",
    "        data_x_list.append(data_x)\n",
    "        data_y_list.append(data_y)\n",
    "        if len(data_x_list) >= batch_size:\n",
    "            data_x = np.array(data_x_list)\n",
    "            data_y = np.array(data_y_list)\n",
    "            data_x = np.transpose(data_x, (0, 1, 4, 2, 3))\n",
    "            data_y = np.transpose(data_y, (0, 1, 4, 2, 3))\n",
    "            save_to_h5(f'dataset_{folder}_sorted_test.h5', f'X_{folder}', data_x)\n",
    "            save_to_h5(f'dataset_{folder}_sorted_test.h5', f'Y_{folder}', data_y)\n",
    "            data_x_list.clear()\n",
    "            data_y_list.clear()\n",
    "            batch_count += 1\n",
    "            print(f\"Processed batch {batch_count} for folder {folder}\")\n",
    "\n",
    "    if data_x_list:\n",
    "        data_x = np.array(data_x_list)\n",
    "        data_y = np.array(data_y_list)\n",
    "        data_x = np.transpose(data_x, (0, 1, 4, 2, 3))\n",
    "        data_y = np.transpose(data_y, (0, 1, 4, 2, 3))\n",
    "        save_to_h5(f'dataset_{folder}_sorted_test.h5', f'X_{folder}', data_x)\n",
    "        save_to_h5(f'dataset_{folder}_sorted_test.h5', f'Y_{folder}', data_y)\n",
    "\n",
    "\n",
    "final_dataset = {}\n",
    "# for folder in folders:\n",
    "with h5py.File(f'dataset_{folder}_sorted_test.h5', 'r') as h5f:\n",
    "        final_dataset[f'X_{folder}'] = np.array(h5f[f'X_{folder}'])\n",
    "        final_dataset[f'Y_{folder}'] = np.array(h5f[f'Y_{folder}'])\n",
    "\n",
    "with open('100_gif_augumentation.pkl', 'wb') as f:\n",
    "    pickle.dump(final_dataset, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbb0f3-35cd-4b3d-8955-79e8e2273fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-OpenSTL]",
   "language": "python",
   "name": "conda-env-.conda-OpenSTL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
